{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16f412fd2ad81ff4",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T02:43:57.027053520Z",
     "start_time": "2023-12-01T02:43:56.986437173Z"
    }
   },
   "outputs": [],
   "source": [
    "from tf_keras.src.datasets import mnist\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def draw_number(pixels):\n",
    "    plt.figure()\n",
    "    plt.imshow(pixels)\n",
    "    plt.colorbar()\n",
    "    plt.grid(False)\n",
    "    plt.show()\n",
    "\n",
    "def load_emnist(key_path):\n",
    "    import os\n",
    "    if not os.path.isfile(\"~/.kaggle/kaggle.json\"):\n",
    "        !mkdir ~/.kaggle\n",
    "        !mv {key_path} ~/.kaggle/kaggle.json\n",
    "        !chmod 600 ~/.kaggle/kaggle.json\n",
    "        !pip install kaggle\n",
    "        !kaggle datasets download -d crawford/emnist -p data\n",
    "\n",
    "        import zipfile\n",
    "        with zipfile.ZipFile(\"data/emnist.zip\", 'r') as zip_ref:\n",
    "            zip_ref.extractall(\"data/emnist\")\n",
    "            \n",
    "            \n",
    "def resize_images(imgs): \n",
    "    res = []\n",
    "    for img in imgs:\n",
    "        r = img.reshape(28, 28).astype('uint8')\n",
    "        b = Image.fromarray(r)\n",
    "        f = b.resize((32, 32))\n",
    "        \n",
    "        res.append(np.array(f).astype('float32') / 255.0)\n",
    "    \n",
    "    return np.array(res)\n",
    "\n",
    "def load_letters():\n",
    "    data = []\n",
    "    letter_labels = []\n",
    "\n",
    "    for row in open(\"data/emnist/emnist-letters-train.csv\"):\n",
    "        row = row.split(\",\")\n",
    "        label = int(row[0])\n",
    "        image = np.array([int(i) for i in row[1:]], dtype=\"uint8\")\n",
    "\n",
    "        image = image.reshape((28, 28))\n",
    "\n",
    "        data.append(image)\n",
    "        letter_labels.append(label)\n",
    "\n",
    "    for row in open(\"data/emnist/emnist-letters-test.csv\"):\n",
    "        row = row.split(\",\")\n",
    "        label = int(row[0])\n",
    "        image = np.array([int(i) for i in row[1:]], dtype=\"uint8\")\n",
    "\n",
    "        image = image.reshape((28, 28))\n",
    "\n",
    "        data.append(image)\n",
    "        letter_labels.append(label)\n",
    "\n",
    "    data = np.array(data, dtype=\"float32\")\n",
    "    letter_labels = np.array(letter_labels, dtype=\"int\")\n",
    "\n",
    "    return data, letter_labels\n",
    "\n",
    "\n",
    "def load_numbers():\n",
    "    (trainData, trainLabels), (testData, testLabels) = mnist.load_data()\n",
    "    data = np.vstack([trainData, testData])\n",
    "    num_labels = np.hstack([trainLabels, testLabels])\n",
    "\n",
    "    return data, num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d82229eb669cf2f5",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T22:49:43.741027267Z",
     "start_time": "2023-11-27T22:49:23.043653691Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/home/slinky/.kaggle’: File exists\r\n",
      "mv: cannot stat 'kaggle.json': No such file or directory\r\n",
      "Requirement already satisfied: kaggle in ./venv/lib/python3.11/site-packages (1.5.16)\r\n",
      "Requirement already satisfied: six>=1.10 in ./venv/lib/python3.11/site-packages (from kaggle) (1.16.0)\r\n",
      "Requirement already satisfied: certifi in ./venv/lib/python3.11/site-packages (from kaggle) (2023.7.22)\r\n",
      "Requirement already satisfied: python-dateutil in ./venv/lib/python3.11/site-packages (from kaggle) (2.8.2)\r\n",
      "Requirement already satisfied: requests in ./venv/lib/python3.11/site-packages (from kaggle) (2.31.0)\r\n",
      "Requirement already satisfied: tqdm in ./venv/lib/python3.11/site-packages (from kaggle) (4.66.1)\r\n",
      "Requirement already satisfied: python-slugify in ./venv/lib/python3.11/site-packages (from kaggle) (8.0.1)\r\n",
      "Requirement already satisfied: urllib3 in ./venv/lib/python3.11/site-packages (from kaggle) (2.1.0)\r\n",
      "Requirement already satisfied: bleach in ./venv/lib/python3.11/site-packages (from kaggle) (6.1.0)\r\n",
      "Requirement already satisfied: webencodings in ./venv/lib/python3.11/site-packages (from bleach->kaggle) (0.5.1)\r\n",
      "Requirement already satisfied: text-unidecode>=1.3 in ./venv/lib/python3.11/site-packages (from python-slugify->kaggle) (1.3)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.11/site-packages (from requests->kaggle) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.11/site-packages (from requests->kaggle) (3.4)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.3.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "emnist.zip: Skipping, found more recently modified local copy (use --force to force download)\r\n"
     ]
    }
   ],
   "source": [
    "load_emnist(\"kaggle.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tf_keras.src import backend, callbacks\n",
    "from tf_keras.src.optimizers import SGD\n",
    "from tf_keras.src.preprocessing.image import ImageDataGenerator\n",
    "from tf_keras.src.regularizers import l2\n",
    "from tf_keras.src.layers import Activation\n",
    "from tf_keras.src.layers import Flatten, Dense, BatchNormalization, AveragePooling2D, Conv2D, add\n",
    "from tf_keras import Model, Input\n",
    "import numpy as np\n",
    "\n",
    "img_shape = (32, 32, 1)\n",
    "chanDim = -1\n",
    "\n",
    "#hyperparameters\n",
    "eps = 2e-5\n",
    "reg = 0.0005\n",
    "mom = 0.9\n",
    "lr = 1e-1\n",
    "batch_size = 128\n",
    "epochs = 50\n",
    "\n",
    "def get_residual(d, k, s, r=False):\n",
    "    short = d\n",
    "\n",
    "    # First block of ResNet (1x1)\n",
    "    bn1 = BatchNormalization(axis=chanDim, epsilon=eps,\n",
    "        momentum=mom)(d)\n",
    "    act1 = Activation(\"relu\")(bn1)\n",
    "    conv1 = Conv2D(int(k * 0.25), (1, 1), use_bias=False,\n",
    "        kernel_regularizer=l2(reg))(act1)\n",
    "\n",
    "    # Second block of ResNet (3x3)\n",
    "    bn2 = BatchNormalization(axis=chanDim, epsilon=eps,\n",
    "        momentum=mom)(conv1)\n",
    "    act2 = Activation(\"relu\")(bn2)\n",
    "    conv2 = Conv2D(int(k * 0.25), (3, 3), strides=s,\n",
    "        padding=\"same\", use_bias=False,\n",
    "        kernel_regularizer=l2(reg))(act2)\n",
    "\n",
    "    # Third block of ResNet (1x1)\n",
    "    bn3 = BatchNormalization(axis=chanDim, epsilon=eps,\n",
    "        momentum=mom)(conv2)\n",
    "    act3 = Activation(\"relu\")(bn3)\n",
    "    conv3 = Conv2D(k, (1, 1), use_bias=False,\n",
    "        kernel_regularizer=l2(reg))(act3)\n",
    "\n",
    "    if r:\n",
    "        short = Conv2D(k, (1, 1), strides=s,\n",
    "            use_bias=False, kernel_regularizer=l2(reg))(act1)\n",
    "\n",
    "    out = add([conv3, short])\n",
    "\n",
    "    return out\n",
    "\n",
    "(letters_images, letters_labels) = load_letters()\n",
    "(digits_images, digits_labels) = load_numbers()\n",
    "    \n",
    "# Letter labels will start at 10, numbers are 0-9\n",
    "letters_labels += 10\n",
    "\n",
    "images = np.vstack([letters_images, digits_images])\n",
    "labels = np.hstack([letters_labels, digits_labels])\n",
    "\n",
    "# resize to fit ResNet architecture\n",
    "images = [cv2.resize(i, (32, 32)) for i in images]\n",
    "images = np.array(images, dtype=\"float32\")\n",
    "\n",
    "images = np.expand_dims(images, axis=-1)\n",
    "images /= 255.0 # normalize\n",
    "\n",
    "LB = LabelBinarizer()\n",
    "labels = LB.fit_transform(labels)\n",
    "\n",
    "totals = labels.sum(axis=0)\n",
    "weights = {}\n",
    "\n",
    "# loop over all classes and calculate the class weight\n",
    "for i in range(0, len(totals)):\n",
    "\tweights[i] = totals.max() / totals[i]\n",
    "    \n",
    "(train_images, test_images, train_labels, test_labels) = train_test_split(images,\n",
    "\tlabels, test_size=0.20, stratify=labels, random_state=42)\n",
    "\n",
    "dataGen = ImageDataGenerator(\n",
    "\trotation_range=10,\n",
    "\tzoom_range=0.05,\n",
    "\twidth_shift_range=0.1,\n",
    "\theight_shift_range=0.1,\n",
    "\tshear_range=0.15,\n",
    "\thorizontal_flip=False,\n",
    "\tfill_mode=\"nearest\")\n",
    "\n",
    "stages = (3, 3, 3)\n",
    "filters = (64, 64, 128, 256)\n",
    "\n",
    "if backend.image_data_format() == \"channels_first\":\n",
    "    img_shape = (1, 32, 32)\n",
    "    chanDim = 1\n",
    "\n",
    "inputs = Input(shape=img_shape)\n",
    "x = BatchNormalization(axis=-1, epsilon=eps,\n",
    "    momentum=mom)(inputs)\n",
    "x = Conv2D(filters[0], (3, 3), use_bias=False,\n",
    "    padding=\"same\", kernel_regularizer=l2(reg))(x)\n",
    "\n",
    "for i in range(0, len(stages)):\n",
    "    stride = (1, 1) if i == 0 else (2, 2)\n",
    "    x = get_residual(x, filters[i + 1], stride, r=True)\n",
    "\n",
    "    for j in range(0, stages[i] - 1):\n",
    "        x = get_residual(x, filters[i + 1], (1, 1))\n",
    "\n",
    "x = BatchNormalization(axis=chanDim, epsilon=eps,\n",
    "    momentum=mom)(x)\n",
    "x = Activation(\"relu\")(x)\n",
    "x = AveragePooling2D((8, 8))(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dense(len(LB.classes_), kernel_regularizer=l2(reg))(x)\n",
    "x = Activation(\"softmax\")(x)\n",
    "\n",
    "# create the model\n",
    "model = Model(inputs, x, name=\"ResNet\")\n",
    "opt = SGD(learning_rate=lr, decay=lr / epochs)\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
    "\tmetrics=[\"accuracy\"])\n",
    "\n",
    "model_checkpoint_callback = callbacks.ModelCheckpoint(\n",
    "    filepath='model',\n",
    "    save_best_only=True, \n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    verbose=1)\n",
    "\n",
    "# Callback for early stopping\n",
    "early_stopping_callback = callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,  # Number of epochs with no improvement after which training will be stopped\n",
    "    verbose=1,\n",
    "    mode='min',\n",
    "    restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    dataGen.flow(train_images, train_labels, batch_size=batch_size),\n",
    "\tvalidation_data=(test_images, test_labels),\n",
    "\tsteps_per_epoch=len(train_images) // batch_size,\n",
    "\tepochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    class_weight=weights,\n",
    "    callbacks=[model_checkpoint_callback, early_stopping_callback],\n",
    "\tverbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "5b677bf0cf4e1cd4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "2f636dfbff1319e2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
